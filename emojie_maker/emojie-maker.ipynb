{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importinng the Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom keras import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.optimizers import Adam\nfrom keras.layers import MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\npathlib.Path('./model.h5').parent.absolute()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"PosixPath('/kaggle/working')"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = '../input/fer2013/train'\nval_dir = '../input/fer2013/test'\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(48,48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')\nvalidation_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size=(48,48),\n        batch_size=64,\n        color_mode=\"grayscale\",\n        class_mode='categorical')","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_model = Sequential()\nemotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\nemotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation='relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\nemotion_model_info = emotion_model.fit_generator(\n        train_generator,\n        steps_per_epoch=28709 // 64,\n        epochs=50,\n        validation_data=validation_generator,\n        validation_steps=7178 // 64)","execution_count":8,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n448/448 [==============================] - 68s 153ms/step - loss: 1.8044 - accuracy: 0.2583 - val_loss: 1.7447 - val_accuracy: 0.3202\nEpoch 2/50\n448/448 [==============================] - 23s 52ms/step - loss: 1.6413 - accuracy: 0.3631 - val_loss: 1.5750 - val_accuracy: 0.4044\nEpoch 3/50\n448/448 [==============================] - 23s 51ms/step - loss: 1.5403 - accuracy: 0.4078 - val_loss: 1.4784 - val_accuracy: 0.4315\nEpoch 4/50\n448/448 [==============================] - 24s 54ms/step - loss: 1.4724 - accuracy: 0.4358 - val_loss: 1.4134 - val_accuracy: 0.4625\nEpoch 5/50\n448/448 [==============================] - 23s 50ms/step - loss: 1.4141 - accuracy: 0.4599 - val_loss: 1.3833 - val_accuracy: 0.4759\nEpoch 6/50\n448/448 [==============================] - 22s 49ms/step - loss: 1.3686 - accuracy: 0.4797 - val_loss: 1.3362 - val_accuracy: 0.4979\nEpoch 7/50\n448/448 [==============================] - 23s 51ms/step - loss: 1.3249 - accuracy: 0.4984 - val_loss: 1.3003 - val_accuracy: 0.5070\nEpoch 8/50\n448/448 [==============================] - 23s 52ms/step - loss: 1.2841 - accuracy: 0.5143 - val_loss: 1.2628 - val_accuracy: 0.5181\nEpoch 9/50\n448/448 [==============================] - 22s 49ms/step - loss: 1.2504 - accuracy: 0.5274 - val_loss: 1.2360 - val_accuracy: 0.5286\nEpoch 10/50\n448/448 [==============================] - 23s 51ms/step - loss: 1.2175 - accuracy: 0.5424 - val_loss: 1.2317 - val_accuracy: 0.5331\nEpoch 11/50\n448/448 [==============================] - 22s 49ms/step - loss: 1.1879 - accuracy: 0.5535 - val_loss: 1.2208 - val_accuracy: 0.5339\nEpoch 12/50\n448/448 [==============================] - 22s 50ms/step - loss: 1.1600 - accuracy: 0.5640 - val_loss: 1.1861 - val_accuracy: 0.5490\nEpoch 13/50\n448/448 [==============================] - 22s 50ms/step - loss: 1.1333 - accuracy: 0.5739 - val_loss: 1.1658 - val_accuracy: 0.5621\nEpoch 14/50\n448/448 [==============================] - 22s 49ms/step - loss: 1.1110 - accuracy: 0.5825 - val_loss: 1.1548 - val_accuracy: 0.5657\nEpoch 15/50\n448/448 [==============================] - 22s 50ms/step - loss: 1.0880 - accuracy: 0.5920 - val_loss: 1.1697 - val_accuracy: 0.5600\nEpoch 16/50\n448/448 [==============================] - 21s 48ms/step - loss: 1.0639 - accuracy: 0.6020 - val_loss: 1.1313 - val_accuracy: 0.5718\nEpoch 17/50\n448/448 [==============================] - 22s 49ms/step - loss: 1.0426 - accuracy: 0.6125 - val_loss: 1.1185 - val_accuracy: 0.5795\nEpoch 18/50\n448/448 [==============================] - 24s 53ms/step - loss: 1.0191 - accuracy: 0.6208 - val_loss: 1.1100 - val_accuracy: 0.5797\nEpoch 19/50\n448/448 [==============================] - 23s 51ms/step - loss: 0.9938 - accuracy: 0.6306 - val_loss: 1.1068 - val_accuracy: 0.5865\nEpoch 20/50\n448/448 [==============================] - 26s 58ms/step - loss: 0.9778 - accuracy: 0.6396 - val_loss: 1.1187 - val_accuracy: 0.5824\nEpoch 21/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.9517 - accuracy: 0.6496 - val_loss: 1.1066 - val_accuracy: 0.5889\nEpoch 22/50\n448/448 [==============================] - 28s 63ms/step - loss: 0.9264 - accuracy: 0.6618 - val_loss: 1.0827 - val_accuracy: 0.5960\nEpoch 23/50\n448/448 [==============================] - 28s 62ms/step - loss: 0.9094 - accuracy: 0.6639 - val_loss: 1.0866 - val_accuracy: 0.5972\nEpoch 24/50\n448/448 [==============================] - 28s 62ms/step - loss: 0.8811 - accuracy: 0.6765 - val_loss: 1.0767 - val_accuracy: 0.6041\nEpoch 25/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.8605 - accuracy: 0.6844 - val_loss: 1.0938 - val_accuracy: 0.6039\nEpoch 26/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.8400 - accuracy: 0.6902 - val_loss: 1.0826 - val_accuracy: 0.6066\nEpoch 27/50\n448/448 [==============================] - 30s 66ms/step - loss: 0.8150 - accuracy: 0.7029 - val_loss: 1.0675 - val_accuracy: 0.6042\nEpoch 28/50\n448/448 [==============================] - 28s 62ms/step - loss: 0.8006 - accuracy: 0.7050 - val_loss: 1.0679 - val_accuracy: 0.6084\nEpoch 29/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.7720 - accuracy: 0.7183 - val_loss: 1.0806 - val_accuracy: 0.6088\nEpoch 30/50\n448/448 [==============================] - 27s 60ms/step - loss: 0.7520 - accuracy: 0.7237 - val_loss: 1.0796 - val_accuracy: 0.6099\nEpoch 31/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.7318 - accuracy: 0.7346 - val_loss: 1.0625 - val_accuracy: 0.6115\nEpoch 32/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.7127 - accuracy: 0.7402 - val_loss: 1.0745 - val_accuracy: 0.6127\nEpoch 33/50\n448/448 [==============================] - 23s 52ms/step - loss: 0.6865 - accuracy: 0.7508 - val_loss: 1.0781 - val_accuracy: 0.6161\nEpoch 34/50\n448/448 [==============================] - 22s 48ms/step - loss: 0.6707 - accuracy: 0.7553 - val_loss: 1.0815 - val_accuracy: 0.6155\nEpoch 35/50\n448/448 [==============================] - 22s 49ms/step - loss: 0.6496 - accuracy: 0.7619 - val_loss: 1.0813 - val_accuracy: 0.6154\nEpoch 36/50\n448/448 [==============================] - 24s 54ms/step - loss: 0.6277 - accuracy: 0.7733 - val_loss: 1.0945 - val_accuracy: 0.6159\nEpoch 37/50\n448/448 [==============================] - 27s 60ms/step - loss: 0.6169 - accuracy: 0.7734 - val_loss: 1.0945 - val_accuracy: 0.6194\nEpoch 38/50\n448/448 [==============================] - 30s 66ms/step - loss: 0.5942 - accuracy: 0.7826 - val_loss: 1.0945 - val_accuracy: 0.6189\nEpoch 39/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.5698 - accuracy: 0.7952 - val_loss: 1.0911 - val_accuracy: 0.6204\nEpoch 40/50\n448/448 [==============================] - 24s 55ms/step - loss: 0.5526 - accuracy: 0.7979 - val_loss: 1.0944 - val_accuracy: 0.6189\nEpoch 41/50\n448/448 [==============================] - 24s 54ms/step - loss: 0.5357 - accuracy: 0.8058 - val_loss: 1.1062 - val_accuracy: 0.6223\nEpoch 42/50\n448/448 [==============================] - 24s 53ms/step - loss: 0.5164 - accuracy: 0.8119 - val_loss: 1.1162 - val_accuracy: 0.6191\nEpoch 43/50\n448/448 [==============================] - 24s 54ms/step - loss: 0.5024 - accuracy: 0.8196 - val_loss: 1.1301 - val_accuracy: 0.6244\nEpoch 44/50\n448/448 [==============================] - 27s 61ms/step - loss: 0.4862 - accuracy: 0.8243 - val_loss: 1.1360 - val_accuracy: 0.6196\nEpoch 45/50\n448/448 [==============================] - 28s 61ms/step - loss: 0.4749 - accuracy: 0.8287 - val_loss: 1.1403 - val_accuracy: 0.6221\nEpoch 46/50\n448/448 [==============================] - 25s 56ms/step - loss: 0.4585 - accuracy: 0.8335 - val_loss: 1.1698 - val_accuracy: 0.6184\nEpoch 47/50\n448/448 [==============================] - 26s 57ms/step - loss: 0.4427 - accuracy: 0.8405 - val_loss: 1.1402 - val_accuracy: 0.6228\nEpoch 48/50\n448/448 [==============================] - 25s 56ms/step - loss: 0.4293 - accuracy: 0.8453 - val_loss: 1.1606 - val_accuracy: 0.6222\nEpoch 49/50\n448/448 [==============================] - 26s 57ms/step - loss: 0.4159 - accuracy: 0.8495 - val_loss: 1.1821 - val_accuracy: 0.6233\nEpoch 50/50\n448/448 [==============================] - 26s 57ms/step - loss: 0.4036 - accuracy: 0.8526 - val_loss: 1.1816 - val_accuracy: 0.6264\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#emotion_model.save_weights('model.h5')\nimport pathlib\npathlib.Path().absolute()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"PosixPath('/kaggle/working')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tkinter as tk\nfrom tkinter import *\nimport matplotlib\nmatplotlib.use('TkAgg')\nimport cv2\nfrom PIL import Image, ImageTk\nimport os\nimport numpy as np\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.optimizers import Adam\nfrom keras.layers import MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nemotion_model = Sequential()\nemotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\nemotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation='relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))\nemotion_model.load_weights('../input/emojieh5/model.h5')\ncv2.ocl.setUseOpenCL(False)\nemotion_dict = {0: \"   Angry   \", 1: \"Disgusted\", 2: \"  Fearful  \", 3: \"   Happy   \", 4: \"  Neutral  \", 5: \"    Sad    \", 6: \"Surprised\"}\nemoji_dist={0:\"../input/emojie/angry.png\",2:\"./input/emojie/disgusted.png\",2:\"./input/emojie/fearful.png\",3:\"./input/emojie/happy.png\",4:\"./input/emojie/neutral.png\",5:\"./input/emojie/sad.png\",6:\"./input/emojie/surpriced.png\"}\nglobal last_frame1                                    \nlast_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\nglobal cap1\nshow_text=[0]\ndef show_vid():      \n    cap1 = cv2.VideoCapture(0)                                 \n    if not cap1.isOpened():                             \n        print(\"cant open the camera1\")\n    flag1, frame1 = cap1.read()\n    frame1 = cv2.resize(frame1,(600,500))\n    bounding_box = cv2.CascadeClassifier('../input/opencvcode/haarcascade_frontalface_default.xml')\n    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n    for (x, y, w, h) in num_faces:\n        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n        prediction = emotion_model.predict(cropped_img)\n        \n        maxindex = int(np.argmax(prediction))\n        cv2.putText(frame1, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n        show_text[0]=maxindex\n    if flag1 is None:\n        print (\"Major error!\")\n    elif flag1:\n        global last_frame1\n        last_frame1 = frame1.copy()\n        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)     \n        img = Image.fromarray(pic)\n        imgtk = ImageTk.PhotoImage(image=img)\n        lmain.imgtk = imgtk\n        lmain.configure(image=imgtk)\n        lmain.after(10, show_vid)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        exit()\ndef show_vid2():\n    frame2=cv2.imread(emoji_dist[show_text[0]])\n    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)\n    img2=Image.fromarray(frame2)\n    imgtk2=ImageTk.PhotoImage(image=img2)\n    lmain2.imgtk2=imgtk2\n    lmain3.configure(text=emotion_dict[show_text[0]],font=('arial',45,'bold'))\n    \n    lmain2.configure(image=imgtk2)\n    lmain2.after(10, show_vid2)\nif __name__ == '__main__':\n    root=tk.Tk()   \n    img = ImageTk.PhotoImage(Image.open(\"../input/emojie/angry.png\"))\n    heading = Label(root,image=img,bg='black')\n    \n    heading.pack() \n    heading2=Label(root,text=\"Photo to Emoji\",pady=20, font=('arial',45,'bold'),bg='black',fg='#CDCDCD')                                 \n    \n    heading2.pack()\n    lmain = tk.Label(master=root,padx=50,bd=10)\n    lmain2 = tk.Label(master=root,bd=10)\n    lmain3=tk.Label(master=root,bd=10,fg=\"#CDCDCD\",bg='black')\n    lmain.pack(side=LEFT)\n    lmain.place(x=50,y=250)\n    lmain3.pack()\n    lmain3.place(x=960,y=250)\n    lmain2.pack(side=RIGHT)\n    lmain2.place(x=900,y=350)\n    \n    root.title(\"Photo To Emoji\")            \n    root.geometry(\"1400x900+100+10\") \n    root['bg']='black'\n    exitbutton = Button(root, text='Quit',fg=\"red\",command=root.destroy,font=('arial',25,'bold')).pack(side = BOTTOM)\n    show_vid()\n    show_vid2()\n    root.mainloop()","execution_count":1,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e141658a6b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TkAgg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 f\"for the old name will be dropped %(removal)s.\")\n\u001b[1;32m    295\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# wrapper() must keep the same documented signature as func(): if we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(backend, warn, force)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;34m\"Cannot load backend {!r} which requires the {!r} interactive \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \"framework, as {!r} is currently running\".format(\n\u001b[0;32m--> 237\u001b[0;31m                     newbackend, required_framework, current_framework))\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParamsDefault\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}