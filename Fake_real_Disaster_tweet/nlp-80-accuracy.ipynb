{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load the Datasets\n",
    "train = pd.read_csv(\"../../Large_data/nlp-getting-started/train.csv\")\n",
    "test = pd.read_csv(\"../../Large_data/nlp-getting-started/test.csv\")\n",
    "submission = pd.read_csv(\"../../Large_data//nlp-getting-started/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 row for train dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 row for test dataset\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape (7613, 5)\n",
      "Test dataset shape (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset shape {train.shape}\")\n",
    "print(f\"Test dataset shape {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value for train dataset: id          0.000000\n",
      "keyword     0.008013\n",
      "location    0.332720\n",
      "text        0.000000\n",
      "target      0.000000\n",
      "dtype: float64\n",
      "--------------------\n",
      "Null value for train dataset: id          0.000000\n",
      "keyword     0.007968\n",
      "location    0.338645\n",
      "text        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Null value for train dataset: {train.isnull().mean()}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"Null value for train dataset: {test.isnull().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Keyword and location columns\n",
    "train = train.drop(labels=['keyword','location'], axis=1)\n",
    "test = test.drop(labels=['keyword','location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(name):\n",
    "    # Replace email addresses with 'email'\n",
    "    processed = name.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                     'emailaddress')\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                      'webaddress')\n",
    "\n",
    "    # Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "\n",
    "    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                      'phonenumbr')\n",
    "\n",
    "    # Replace numbers with 'numbr'\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "    # change words to lower case - Hello, HELLO, hello are all the same word\n",
    "    processed = processed.str.lower()\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = clean_data(train[\"text\"])\n",
    "clean_test = clean_data(test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data), are referred to as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "clean_train = clean_train.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "clean_test = clean_test.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            deeds reason earthquake may allah forgive us\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       residents asked shelter place notified officer...\n",
       "3       numbr numbr people receive wildfires evacuatio...\n",
       "4       got sent photo ruby alaska smoke wildfires pou...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding bridge collapse nearb...\n",
       "7609    aria_ahrary thetawniest control wild fires cal...\n",
       "7610    mnumbr numbr numbr utc numbrkm volcano hawaii ...\n",
       "7611    police investigating e bike collided car littl...\n",
       "7612    latest homes razed northern california wildfir...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "clean_train = clean_train.apply(lambda x:\" \".join([ps.stem(word) for word in x.split()]))\n",
    "\n",
    "clean_test = clean_test.apply(lambda x:\" \".join([ps.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               deed reason earthquak may allah forgiv us\n",
       "1                    forest fire near la rong sask canada\n",
       "2       resid ask shelter place notifi offic evacu she...\n",
       "3       numbr numbr peopl receiv wildfir evacu order c...\n",
       "4       got sent photo rubi alaska smoke wildfir pour ...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridg collaps nearbi home...\n",
       "7609    aria_ahrari thetawniest control wild fire cali...\n",
       "7610    mnumbr numbr numbr utc numbrkm volcano hawaii ...\n",
       "7611    polic investig e bike collid car littl portug ...\n",
       "7612    latest home raze northern california wildfir a...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word. Text preprocessing includes both Stemming as well as Lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of lemmatization are:\n",
    "\n",
    "*      Used in comprehensive retrieval systems like search engines.\n",
    "*      Used in compact indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "clean_train = clean_train.apply(lambda x:\" \".join([wl.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "clean_test = clean_test.apply(lambda x:\" \".join([wl.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                happen terribl car crash\n",
       "1           heard earthquak differ citi stay safe everyon\n",
       "2       forest fire spot pond gee flee across street c...\n",
       "3                          apocalyps light spokan wildfir\n",
       "4                typhoon soudelor kill numbr china taiwan\n",
       "                              ...                        \n",
       "3258      earthquak safeti lo angel ûò safeti fasten xrwn\n",
       "3259    storm ri wors last hurrican citi amp numbroth ...\n",
       "3260         green line derail chicago http co utbxlcbiuy\n",
       "3261    meg issu hazard weather outlook hwo http co nu...\n",
       "3262      cityofcalgari activ municip emerg plan yycstorm\n",
       "Name: text, Length: 3263, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = clean_train\n",
    "test[\"text\"] = clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X = train.text\n",
    "y = train.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important libraries\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score function\n",
    "\n",
    "def acc_summary(pipeline, X_train, y_train, X_test, y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "   \n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some model and their performance\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"Bernouli\", \"PassiveAggressiveClassifier\",\n",
    "     \"Naive Bayes\", \"SVC\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    PassiveAggressiveClassifier(max_iter=50),\n",
    "    SVC(kernel=\"linear\")\n",
    "]\n",
    "    \n",
    "zipped_clf = zip(names, classifiers)\n",
    "tvec = TfidfVectorizer()\n",
    "    \n",
    "def compare_clf(classifier=zipped_clf, vectorizer=tvec, n_features=10000, ngram_range=(1, 1)):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n, c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            (\"vectorizer\", vectorizer),\n",
    "            (\"classifier\", c)\n",
    "        ])\n",
    "        clf_acc = acc_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        print(\"Model result for {}\".format(n))\n",
    "        print(c)\n",
    "        result.append((n, clf_acc))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "accuracy score: 70.32%\n",
      "------------------------------\n",
      "Model result for K Nearest Neighbors\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "------------------------------\n",
      "accuracy score: 72.94%\n",
      "------------------------------\n",
      "Model result for Decision Tree\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "------------------------------\n",
      "accuracy score: 78.94%\n",
      "------------------------------\n",
      "Model result for Random Forest\n",
      "RandomForestClassifier()\n",
      "------------------------------\n",
      "accuracy score: 80.69%\n",
      "------------------------------\n",
      "Model result for Logistic Regression\n",
      "LogisticRegression()\n",
      "------------------------------\n",
      "accuracy score: 80.65%\n",
      "------------------------------\n",
      "Model result for Bernouli\n",
      "MultinomialNB()\n",
      "------------------------------\n",
      "accuracy score: 80.91%\n",
      "------------------------------\n",
      "Model result for PassiveAggressiveClassifier\n",
      "BernoulliNB()\n",
      "------------------------------\n",
      "accuracy score: 73.34%\n",
      "------------------------------\n",
      "Model result for Naive Bayes\n",
      "PassiveAggressiveClassifier(max_iter=50)\n",
      "------------------------------\n",
      "accuracy score: 79.77%\n",
      "------------------------------\n",
      "Model result for SVC\n",
      "SVC(kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "trigram_result = compare_clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('K Nearest Neighbors', 0.7031523642732049),\n",
       " ('Decision Tree', 0.7294220665499125),\n",
       " ('Random Forest', 0.7894045534150613),\n",
       " ('Logistic Regression', 0.8069176882661997),\n",
       " ('Bernouli', 0.8064798598949212),\n",
       " ('PassiveAggressiveClassifier', 0.809106830122592),\n",
       " ('Naive Bayes', 0.7333625218914186),\n",
       " ('SVC', 0.797723292469352)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TfidfVectorizer\n",
    "# use of pipeline\n",
    "vectorizer=TfidfVectorizer()\n",
    "pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', LogisticRegression())\n",
    "        ])\n",
    "vectorizer.set_params(stop_words=None, max_features=100000, ngram_range=(1,4))\n",
    "sentiment_fit = pipeline.fit(X_train,y_train)\n",
    "y_pred = sentiment_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802101576182137"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sentiment_fit, open('RealOrfake.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('RealOrfake.pkl','rb'))\n",
    "series = pd.Series(\"This is  bitches, flood and earthquake\")\n",
    "data = clean_data(series)\n",
    "value = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real tweet\n"
     ]
    }
   ],
   "source": [
    "if value == 1:\n",
    "    print(\"Real tweet\")\n",
    "else:\n",
    "    print(\"fake tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(name):\n",
    "    processed = name.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumbr')\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    processed = processed.str.lower()\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
